{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Тонкая настройка обучения моделей через метод compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 22:18:08.695272: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-04 22:18:08.856997: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-04 22:18:08.903658: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 702us/step - accuracy: 0.8811 - loss: 0.4091\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.9662 - loss: 0.1086\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.9780 - loss: 0.0711\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706us/step - accuracy: 0.9843 - loss: 0.0528\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.9877 - loss: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7277ac093f10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 767us/step - categorical_accuracy: 0.8941 - loss: 0.3539\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - categorical_accuracy: 0.9524 - loss: 0.1732\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - categorical_accuracy: 0.9592 - loss: 0.1500\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726us/step - categorical_accuracy: 0.9653 - loss: 0.1344\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - categorical_accuracy: 0.9650 - loss: 0.1325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7277abf21310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model2.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 682us/step - categorical_accuracy: 0.8637 - loss: 0.0203\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - categorical_accuracy: 0.9227 - loss: 0.0134\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - categorical_accuracy: 0.9128 - loss: 0.0164\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - categorical_accuracy: 0.9092 - loss: 0.0175\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.9116 - loss: 0.0173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7277aab64a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#своя функция потерь\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "def myloss(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=myloss,\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 730us/step - categorical_accuracy: 0.8034 - loss: 0.0128\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - categorical_accuracy: 0.8091 - loss: 0.0128\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 694us/step - categorical_accuracy: 0.8203 - loss: 0.0126\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 690us/step - categorical_accuracy: 0.8300 - loss: 0.0124\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - categorical_accuracy: 0.8360 - loss: 0.0123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7277a9711310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#своя функция потерь\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "class MyLoss(keras.losses.Loss):\n",
    "    def __init__(self, alpha=1.0, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.square(self.alpha*y_true - self.beta * y_pred))\n",
    "\n",
    "model3.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=MyLoss(0.5, 0.2),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy()])\n",
    "\n",
    "model3.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 758us/step - categorical_accuracy: 0.8193 - loss: 0.0125 - my_metric: 0.8193\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 758us/step - categorical_accuracy: 0.8201 - loss: 0.0126 - my_metric: 0.2514\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - categorical_accuracy: 0.8339 - loss: 0.0123 - my_metric: 0.1560\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - categorical_accuracy: 0.8401 - loss: 0.0122 - my_metric: 0.1152\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - categorical_accuracy: 0.8124 - loss: 0.0128 - my_metric: 0.0866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72778c220d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#пользовательские метрики\n",
    "\n",
    "model4 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "class MyLoss(keras.losses.Loss):\n",
    "    def __init__(self, alpha=1.0, beta=1.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        return tf.reduce_mean(tf.square(self.alpha*y_true - self.beta * y_pred))\n",
    "    \n",
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name='my_metric'):\n",
    "        super().__init__(name=name)\n",
    "        self.true_positives = self.add_weight(name='acc', initializer='zeros')\n",
    "        self.count = tf.Variable(0.0)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        y_true = tf.reshape(tf.argmax(y_true, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n",
    "        \n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, 'float32')\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "            \n",
    "        values = tf.cast(values, 'float32')\n",
    "        \n",
    "        self.true_positives.assign_add(tf.reduce_mean(values))\n",
    "        self.count.assign_add(1.0)\n",
    "        \n",
    "    def result(self):\n",
    "        return self.true_positives / self.count\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.true_positives.assign(0.0)\n",
    "        self.count.assign(0.0)\n",
    "        \n",
    "\n",
    "model4.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "              loss=MyLoss(0.5, 0.2),\n",
    "              metrics=[keras.metrics.CategoricalAccuracy(), CategoricalTruePositives()])\n",
    "\n",
    "model4.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - class_output_accuracy: 0.9066 - class_output_loss: 0.2924 - dec_output_accuracy: 0.7882 - dec_output_loss: 0.0556 - loss: 0.3481\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - class_output_accuracy: 0.9701 - class_output_loss: 0.1058 - dec_output_accuracy: 0.7977 - dec_output_loss: 0.0409 - loss: 0.1467\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - class_output_accuracy: 0.9732 - class_output_loss: 0.0998 - dec_output_accuracy: 0.7980 - dec_output_loss: 0.0399 - loss: 0.1397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7277a4b7c650>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "#вектор скрытого состояния\n",
    "enc_input = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(enc_input)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "hidden_output = layers.Dense(8, activation='linear')(x)\n",
    "\n",
    "\n",
    "#восстановление изображения\n",
    "x = layers.Dense(7 * 7 * 8, activation='relu')(hidden_output)\n",
    "x = layers.Reshape((7, 7, 8))(x)\n",
    "x = layers.Conv2DTranspose(64, 5, strides=(2, 2), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Convolution2DTranspose(32, 5, strides=(2, 2), activation='linear', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "dec_output = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same', name='dec_output')(x)\n",
    "\n",
    "#классификация результата\n",
    "x2 = layers.Dense(128, activation='relu')(hidden_output)\n",
    "class_output = layers.Dense(10, activation='softmax', name='class_output')(x2)\n",
    "\n",
    "model5 = keras.Model(enc_input, [dec_output, class_output])\n",
    "\n",
    "model5.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "               loss = ['mean_squared_error', 'categorical_crossentropy'],\n",
    "               metrics=['accuracy', 'accuracy'])\n",
    "\n",
    "model5.fit(x_train, [x_train, y_train], epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#вектор скрытого состояния\n",
    "enc_input = layers.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation='relu')(enc_input)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = layers.MaxPooling2D(2, padding='same')(x)\n",
    "x = layers.Flatten()(x)\n",
    "hidden_output = layers.Dense(8, activation='linear')(x)\n",
    "\n",
    "\n",
    "#восстановление изображения\n",
    "x = layers.Dense(7 * 7 * 8, activation='relu')(hidden_output)\n",
    "x = layers.Reshape((7, 7, 8))(x)\n",
    "x = layers.Conv2DTranspose(64, 5, strides=(2, 2), activation='relu', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Convolution2DTranspose(32, 5, strides=(2, 2), activation='linear', padding='same')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "dec_output = layers.Conv2DTranspose(1, 3, activation='sigmoid', padding='same', name='dec_output')(x)\n",
    "\n",
    "#классификация результата\n",
    "x2 = layers.Dense(128, activation='relu')(hidden_output)\n",
    "class_output = layers.Dense(10, activation='softmax', name='class_output')(x2)\n",
    "\n",
    "model7 = keras.Model(enc_input, [dec_output, class_output])\n",
    "\n",
    "model7.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "               loss = {\n",
    "                   'dec_output' : 'mean_squared_error',\n",
    "                   'class_output' : 'categorical_crossentropy'},\n",
    "               loss_weights = [1.0, 0.5],\n",
    "               metrics={\n",
    "                   'dec_output' : None,\n",
    "                   'class_output' : 'acc'\n",
    "               })\n",
    "\n",
    "model7.fit(x_train, [x_train, y_train], epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "[7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = model7.predict(tf.expand_dims(x_test[0], axis=0))\n",
    "\n",
    "print(tf.argmax(p[1], axis=1).numpy())\n",
    "\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(x_test[0], cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(p[0].squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
