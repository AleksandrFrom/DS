{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Тонкая настройка и контроль процесса обучения через метод fit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 22:03:35.834647: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-01 22:03:35.982881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-01 22:03:36.025696: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.4881\n",
      "Epoch 2/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.9618 - loss: 0.1244\n",
      "Epoch 3/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 851us/step - accuracy: 0.9765 - loss: 0.0792\n",
      "Epoch 4/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.9824 - loss: 0.0571\n",
      "Epoch 5/5\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.9872 - loss: 0.0429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228ff13a4d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8436 - loss: 0.5477 - val_accuracy: 0.9528 - val_loss: 0.1617\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9569 - loss: 0.1428 - val_accuracy: 0.9636 - val_loss: 0.1251\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9717 - loss: 0.0945 - val_accuracy: 0.9650 - val_loss: 0.1156\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9813 - loss: 0.0677 - val_accuracy: 0.9668 - val_loss: 0.1129\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.9858 - loss: 0.0506 - val_accuracy: 0.9675 - val_loss: 0.1119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228fc86c4d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#параметры валидации\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "model2 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model2.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train_data, y_train_data, batch_size=64, epochs=5, validation_data=(x_train_val, y_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8362 - loss: 0.5782 - val_accuracy: 0.9479 - val_loss: 0.1741\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9550 - loss: 0.1540 - val_accuracy: 0.9622 - val_loss: 0.1248\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9722 - loss: 0.0980 - val_accuracy: 0.9643 - val_loss: 0.1174\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9773 - loss: 0.0716 - val_accuracy: 0.9732 - val_loss: 0.0912\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9838 - loss: 0.0538 - val_accuracy: 0.9738 - val_loss: 0.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228fc6c5ed0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#параметры валидации tf.data\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model3 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model3.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model3.fit(train_dataset, epochs=5, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6001 - loss: 1.3832 - val_accuracy: 0.8936 - val_loss: 0.3731\n",
      "Epoch 2/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3267 - val_accuracy: 0.9215 - val_loss: 0.2754\n",
      "Epoch 3/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2756 - val_accuracy: 0.9283 - val_loss: 0.2368\n",
      "Epoch 4/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2552 - val_accuracy: 0.9365 - val_loss: 0.2144\n",
      "Epoch 5/5\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.2159 - val_accuracy: 0.9398 - val_loss: 0.1960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228ff111d50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#steps_per_epoch and validation_steps\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model4 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model4.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model4.fit(train_dataset, epochs=5,steps_per_epoch=100, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8378 - loss: 0.5623 - val_accuracy: 0.9531 - val_loss: 0.1638\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 962us/step - accuracy: 0.9559 - loss: 0.1487 - val_accuracy: 0.9750 - val_loss: 0.1194\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step - accuracy: 0.9708 - loss: 0.0962 - val_accuracy: 0.9531 - val_loss: 0.1161\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9786 - loss: 0.0706 - val_accuracy: 0.9375 - val_loss: 0.2044\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 991us/step - accuracy: 0.9828 - loss: 0.0538 - val_accuracy: 0.9719 - val_loss: 0.1002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228fc24c4d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model5 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model5.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model5.fit(train_dataset, epochs=5, validation_data=val_dataset, validation_steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3939 - loss: 10.6588 - val_accuracy: 0.7895 - val_loss: 0.7669\n",
      "Epoch 2/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7367 - loss: 1.2522 - val_accuracy: 0.8301 - val_loss: 0.6233\n",
      "Epoch 3/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8316 - loss: 0.7256 - val_accuracy: 0.8863 - val_loss: 0.4168\n",
      "Epoch 4/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8843 - loss: 0.4586 - val_accuracy: 0.9137 - val_loss: 0.3109\n",
      "Epoch 5/5\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.3406 - val_accuracy: 0.9267 - val_loss: 0.2653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228f41ac4d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#изменение весов для выходных значений\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model6 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model6.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "class_weight = {\n",
    "    0: 1000.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    5: 1.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "model6.fit(train_dataset, epochs=5, validation_data=val_dataset, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 706us/step - accuracy: 0.8645 - loss: 0.5022\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 678us/step - accuracy: 0.9648 - loss: 0.1260\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.9760 - loss: 0.0842\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.9832 - loss: 0.0583\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.9876 - loss: 0.0438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228ff18c510>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "sample_weight = np.ones(shape=(len(x_train),))\n",
    "sample_weight[y_train == 1] = 5.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model7 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model7.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model7.fit(x_train, y_train, epochs=5, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 896us/step - accuracy: 0.8575 - loss: 0.4859 - val_accuracy: 0.9596 - val_loss: 0.1375\n",
      "Epoch 2/3\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 812us/step - accuracy: 0.9611 - loss: 0.1257 - val_accuracy: 0.9718 - val_loss: 0.0975\n",
      "Epoch 3/3\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.9749 - loss: 0.0808 - val_accuracy: 0.9728 - val_loss: 0.0912\n",
      "{'accuracy': [0.9190000295639038, 0.9648541808128357, 0.9771249890327454], 'loss': [0.27640825510025024, 0.11386938393115997, 0.07493723928928375], 'val_accuracy': [0.9595833420753479, 0.971750020980835, 0.9727500081062317], 'val_loss': [0.13748396933078766, 0.0974680483341217, 0.09118197858333588]}\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "sample_weight = np.ones(shape=(len(x_train),))\n",
    "sample_weight[y_train == 1] = 5.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model8 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model8.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model8.fit(x_train, y_train, epochs=3, validation_split=0.2)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m917/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.8476 - loss: 0.5333 on_epoch_end\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8492 - loss: 0.5278  \n",
      "Epoch 2/3\n",
      "\u001b[1m882/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.9628 - loss: 0.1232 on_epoch_end\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.9629 - loss: 0.1228\n",
      "Epoch 3/3\n",
      "\u001b[1m919/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 935us/step - accuracy: 0.9758 - loss: 0.0800 on_epoch_end\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9758 - loss: 0.0800  \n",
      "{'accuracy': [0.9150652289390564, 0.9651827812194824, 0.9758829474449158], 'loss': [0.29755184054374695, 0.11533674597740173, 0.07932576537132263]}\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "sample_weight = np.ones(shape=(len(x_train),))\n",
    "sample_weight[y_train == 1] = 5.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model9 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model9.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class DigitsLimit(keras.utils.Sequence):\n",
    "    def __init__(self, x, y, batch_size, max_len = -1):\n",
    "        self.batch_size = batch_size\n",
    "        self.x = x[:max_len]\n",
    "        self.y = y[:max_len]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.x.shape[0] / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return batch_x, batch_y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        p = np.random.permutation(len(self.x))\n",
    "        self.x = self.x[p]\n",
    "        self.y = self.y[p]\n",
    "        print(' on_epoch_end')\n",
    "\n",
    "sequence = DigitsLimit(x_train, y_train, 64)\n",
    "\n",
    "history = model9.fit(sequence, epochs=3, shuffle=False)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 726us/step - accuracy: 0.8766 - loss: 0.4229\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.9649 - loss: 0.1142\n",
      "Epoch 2: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228f7930ed0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#callbacks обратный вызов\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "sample_weight = np.ones(shape=(len(x_train),))\n",
    "sample_weight[y_train == 1] = 5.0\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "validation_split = 0.2\n",
    "validation_split_index = np.ceil(x_train.shape[0] * validation_split).astype('int32')\n",
    "\n",
    "#обучающая валидации\n",
    "x_train_val = x_train[:validation_split_index]\n",
    "y_train_val = y_train[:validation_split_index]\n",
    "\n",
    "#обучающая выборка\n",
    "x_train_data = x_train[validation_split_index:]\n",
    "y_train_data = y_train[validation_split_index:]\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_train_val, y_train_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model9 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model9.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.5, patience=1, verbose=1)\n",
    "    ]\n",
    "\n",
    "# min_delta =0.01 and patience = 2\n",
    "\n",
    "model9.fit(x_train, y_train, epochs=3, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1836/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.8714 - loss: 0.4305\n",
      "Epoch 1: loss improved from inf to 0.24260, saving model to mymodel_1.keras\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 699us/step - accuracy: 0.8726 - loss: 0.4265\n",
      "Epoch 2/3\n",
      "\u001b[1m1864/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.9663 - loss: 0.1094\n",
      "Epoch 2: loss improved from 0.24260 to 0.10128, saving model to mymodel_2.keras\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.9663 - loss: 0.1093\n",
      "Epoch 3/3\n",
      "\u001b[1m1819/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 692us/step - accuracy: 0.9781 - loss: 0.0717\n",
      "Epoch 3: loss improved from 0.10128 to 0.06842, saving model to mymodel_3.keras\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.9782 - loss: 0.0716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228f73644d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ModelCheckpoint\n",
    "\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "model10 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model10.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='loss', min_delta=0.01, patience=2, verbose=1),\n",
    "    keras.callbacks.ModelCheckpoint(filepath=\"mymodel_{epoch}.keras\", save_best_only='True', monitor='loss', verbose=1 )\n",
    "    ]\n",
    "\n",
    "# min_delta =0.01 and patience = 2\n",
    "\n",
    "model10.fit(x_train, y_train, epochs=3, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model11 = keras.models.load_model('mymodel_3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 427us/step - accuracy: 0.9687 - loss: 0.0924\n",
      "[0.07845163345336914, 0.973800003528595]\n"
     ]
    }
   ],
   "source": [
    "print(model11.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 712us/step - accuracy: 0.8777 - loss: 0.4238\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.9652 - loss: 0.1134\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 778us/step - accuracy: 0.9777 - loss: 0.0733\n",
      "[2.374800682067871, 2.382244825363159, 2.3005878925323486, 2.2811496257781982, 2.25882625579834]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7228f6cc49d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#свой класс для оценки функции потерь\n",
    "\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "#стандартизация данных\n",
    "x_train = x_train.reshape(-1, 784) / 255\n",
    "x_test = x_test.reshape(-1, 784) / 255\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "model12 = keras.Sequential([\n",
    "    layers.Input(shape=(784,)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model12.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "        \n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get('loss'))\n",
    "        \n",
    "    def on_train_end(self, logs):\n",
    "        print(self.per_batch_losses[:5])\n",
    "\n",
    "callbacks = [CustomCallback(),]\n",
    "\n",
    "model12.fit(x_train, y_train, epochs=3, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tens",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
